{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "gOtWGBVrOXxh",
    "outputId": "2f9ebc2a-d574-4d5e-a0f7-79a62bcf6bea"
   },
   "outputs": [],
   "source": [
    "!pip install pyheif\n",
    "\n",
    "from PIL import Image\n",
    "import pyheif\n",
    "\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "from pathlib import Path\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "\n",
    "import PIL.Image as Image\n",
    "import cv2\n",
    "import torch\n",
    "import torchvision\n",
    "from IPython.display import display, clear_output\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch import nn\n",
    "from torchvision import models, transforms as T\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "import pandas as pd\n",
    "from pylab import rcParams\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from matplotlib import rc\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format='retina'\n",
    "sns.set(style='whitegrid', palette='muted', font_scale=1.2)\n",
    "rcParams['figure.figsize'] = 16, 10\n",
    "\n",
    "import os\n",
    "\n",
    "clear_output()\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n",
    "\n",
    "model = torch.hub.load('ultralytics/yolov5', 'custom', path='ПУТЬ К ВЕСАМ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "LMYzV2lpJCku"
   },
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "def seed_all(seed_value):\n",
    "    random.seed(seed_value)\n",
    "    np.random.seed(seed_value)\n",
    "    torch.manual_seed(seed_value)\n",
    "    \n",
    "    if torch.cuda.is_available(): \n",
    "        torch.cuda.manual_seed(seed_value)\n",
    "        torch.cuda.manual_seed_all(seed_value)\n",
    "        torch.backends.cudnn.deterministic = True\n",
    "        torch.backends.cudnn.benchmark = False\n",
    "\n",
    "seed_all(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "s3HR_-L2YZ4M",
    "outputId": "2f3e408c-40c2-466d-9615-bdf563bfa15f"
   },
   "outputs": [],
   "source": [
    "path = 'путь к фото'\n",
    "\n",
    "class_0_title = 'класс 0'\n",
    "class_0_folders = ['папки для 0 класса']\n",
    "\n",
    "class_1_title = 'класс 1'\n",
    "class_1_folders = ['папки для 1 класса']\n",
    "\n",
    "class_2_title = 'класс 2'\n",
    "class_2_folders = ['папки для 2 класса']\n",
    "\n",
    "class_0_imgs = []\n",
    "class_1_imgs = []\n",
    "class_2_imgs = []\n",
    "\n",
    "print('\\tclass 0')\n",
    "for i, folder in enumerate(class_0_folders):\n",
    "    print('folder', i + 1, '/', len(class_0_folders))\n",
    "    for file in tqdm(os.listdir(path=path + '/' + class_0_title + '/' + folder)):\n",
    "        try:\n",
    "            heif_file = pyheif.read(path + '/' + class_0_title + '/' + folder + '/' + file)\n",
    "            image = Image.frombytes(\n",
    "                heif_file.mode,\n",
    "                heif_file.size,\n",
    "                heif_file.data,\n",
    "                \"raw\",\n",
    "                heif_file.mode,\n",
    "                heif_file.stride,\n",
    "            ).resize((416, 416))\n",
    "            class_0_imgs.append(image)\n",
    "        except:\n",
    "            image = Image.open(path + '/' + class_0_title + '/' + folder + '/' + file).resize((416, 416))\n",
    "            class_0_imgs.append(image)\n",
    "\n",
    "print('\\tclass 1')\n",
    "for i, folder in enumerate(class_1_folders):\n",
    "    print('folder', i + 1, '/', len(class_1_folders))\n",
    "    for file in tqdm(os.listdir(path=path + '/' + class_1_title + '/' + folder)):\n",
    "        try:\n",
    "            heif_file = pyheif.read(path + '/' + class_1_title + '/' + folder + '/' + file)\n",
    "            image = Image.frombytes(\n",
    "                heif_file.mode,\n",
    "                heif_file.size,\n",
    "                heif_file.data,\n",
    "                \"raw\",\n",
    "                heif_file.mode,\n",
    "                heif_file.stride,\n",
    "            ).resize((416, 416))\n",
    "            class_1_imgs.append(image)\n",
    "        except:\n",
    "            image = Image.open(path + '/' + class_1_title + '/' + folder + '/' + file).resize((416, 416))\n",
    "            class_1_imgs.append(image)\n",
    "\n",
    "print('\\tclass 2')\n",
    "for i, folder in enumerate(class_2_folders):\n",
    "    print('folder', i + 1, '/', len(class_2_folders))\n",
    "    for file in tqdm(os.listdir(path=path + '/' + class_2_title + '/' + folder)):\n",
    "        try:\n",
    "            heif_file = pyheif.read(path + '/' + class_2_title + '/' + folder + '/' + file)\n",
    "            image = Image.frombytes(\n",
    "                heif_file.mode,\n",
    "                heif_file.size,\n",
    "                heif_file.data,\n",
    "                \"raw\",\n",
    "                heif_file.mode,\n",
    "                heif_file.stride,\n",
    "            ).resize((416, 416))\n",
    "            class_2_imgs.append(image)\n",
    "        except:\n",
    "            image = Image.open(path + '/' + class_2_title + '/' + folder + '/' + file).resize((416, 416))\n",
    "            class_2_imgs.append(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "sxLTQdsYLIYd"
   },
   "outputs": [],
   "source": [
    "drive.flush_and_unmount()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "H2gxqh9tMgpu"
   },
   "outputs": [],
   "source": [
    "os.mkdir('class0')\n",
    "os.mkdir('class1')\n",
    "os.mkdir('class2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "tUIWa6KoTLAQ"
   },
   "outputs": [],
   "source": [
    "for i, image in enumerate(class_0_imgs):\n",
    "    image.save('class0/' + str(i) + '.jpg')\n",
    "for i, image in enumerate(class_1_imgs):\n",
    "    image.save('class1/' + str(i) + '.jpg')\n",
    "for i, image in enumerate(class_2_imgs):\n",
    "    image.save('class2/' + str(i) + '.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "G495R1LqJpjg",
    "outputId": "13d4a8df-76e5-41ac-a799-736f67758124"
   },
   "outputs": [],
   "source": [
    "preds_all = [[], [], []]\n",
    "dirs = ['class0', 'class1', 'class2']\n",
    "imgs_lens = [len(class_0_imgs), len(class_1_imgs), len(class_2_imgs)]\n",
    "for j, dir in enumerate(dirs):\n",
    "    inds = np.arange(imgs_lens[j])\n",
    "    inds1 = inds[ : len(inds) // 100 * 100].reshape((-1, 100))\n",
    "    inds2 = inds[len(inds) // 100 * 100:]\n",
    "    for k in range(inds1.shape[0]):\n",
    "        imgs = [dir + '/' + str(num) + '.jpg' for num in inds1[k]]\n",
    "        model(imgs).save(save_dir='save_dir')\n",
    "        preds = model(imgs).pred\n",
    "        for i in range(len(preds)):\n",
    "            preds[i] = preds[i].cpu()\n",
    "        preds_all[j] += preds\n",
    "    imgs = [dir + '/' + str(num) + '.jpg' for num in inds2]\n",
    "    # model(imgs).save(save_dir='save_dir')\n",
    "    preds = model(imgs).pred\n",
    "    for i in range(len(preds)):\n",
    "        preds[i] = preds[i].cpu()\n",
    "    preds_all[j] += preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "YG_XA6A0t_v4"
   },
   "outputs": [],
   "source": [
    "X = []\n",
    "for preds_per_class in preds_all:\n",
    "    X += preds_per_class\n",
    "y = np.array([0] * len(class_0_imgs) + [1] * len(class_1_imgs) + [2] * len(class_2_imgs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "lwJ45LzYTe3T"
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=0, test_size=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "JxXoUCN5t6mv"
   },
   "outputs": [],
   "source": [
    "class MyDataset(Dataset):\n",
    "    def __init__(self, x, y, max_len):\n",
    "        self.x = x\n",
    "        lens = []\n",
    "        for i in range(len(self.x)):\n",
    "            if self.x[i].shape[0]:\n",
    "                self.x[i] = self.x[i][:, 4:]\n",
    "            else:\n",
    "                self.x[i].reshape((0, 2))\n",
    "            conf = self.x[i][:, 0]\n",
    "            argsort = torch.argsort(conf, dim=0, descending=True)\n",
    "            self.x[i] = self.x[i].flatten()[: max_len * 2].tolist()\n",
    "            self.x[i] += [0.] * (max_len * 2 - len(self.x[i])) + [len(self.x[i])]\n",
    "            \n",
    "        self.y = y.reshape((y.shape[0], 1))\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return torch.tensor(self.x[idx], dtype=torch.float32), torch.tensor(self.y[idx], dtype=torch.float32)\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "DDohOuw1d0Up"
   },
   "outputs": [],
   "source": [
    "BATCH_SIZE = 200\n",
    "\n",
    "max_len = 50\n",
    "\n",
    "train_dataset = MyDataset(X_train, y_train, max_len)\n",
    "test_dataset = MyDataset(X_test, y_test, max_len)\n",
    "\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=2, pin_memory=True)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=2, pin_memory=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vk0bRicQ-qwa"
   },
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.linear = nn.Sequential(\n",
    "           nn.Linear(max_len * 2 + 1, 200),\n",
    "           nn.ReLU(),\n",
    "           nn.Linear(200, 150),\n",
    "           nn.ReLU(),\n",
    "           nn.Linear(150, 3),\n",
    "        )\n",
    "    def forward(self, x):\n",
    "        return self.linear(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "pbPSbj5td0YY"
   },
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "model = torch.load('model_params.pt', map_location=device)\n",
    "model = model.to(device)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss(weight=torch.tensor([y.shape[0] / (y==0).sum(), y.shape[0] / (y==1).sum(), y.shape[0] / (y==2).sum()], dtype=torch.float).to(device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "taajVKXUO3xk",
    "outputId": "4b730ca1-35eb-4a2d-fdc5-63e942647f6e"
   },
   "outputs": [],
   "source": [
    "from IPython.display import display\n",
    "from time import time\n",
    "\n",
    "num_matches = 0\n",
    "model.eval()\n",
    "for x, y in tqdm(test_dataloader):\n",
    "    with torch.no_grad():\n",
    "            \n",
    "        x = x.to(device)\n",
    "        y = y.type(torch.LongTensor).squeeze(1)\n",
    "        logits = model(x).cpu()\n",
    "        num_matches += (np.argmax(logits, 1) == y).sum()\n",
    "        \n",
    "        \n",
    "print('test accuracy = ', num_matches / len(test_dataset))\n",
    "\n",
    "num_matches = 0\n",
    "model.eval()\n",
    "for x, y in tqdm(train_dataloader):\n",
    "    with torch.no_grad():\n",
    "            \n",
    "        x = x.to(device)\n",
    "        y = y.type(torch.LongTensor).squeeze(1)\n",
    "        logits = model(x).cpu()\n",
    "        num_matches += (np.argmax(logits, 1) == y).sum()\n",
    "print('')\n",
    "print('train accuracy = ', num_matches / len(train_dataset))"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "only_heic_classification.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
